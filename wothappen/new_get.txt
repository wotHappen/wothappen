import requests
import json
import http, urllib

import datetime
import matplotlib.pyplot as plt
import numpy as np

from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer as Summarizer
from sumy.nlp.stemmers import Stemmer
from sumy.utils import get_stop_words

ACCESS_KEY = "e58438c7303146b79f63134b261d5b29"
GRAPH_SCALE = 100

# BOT_ID = "Y2lzY29zcGFyazovL3VzL1BFT1BMRS9mNDc5NTE1MS0yODg5LTQ1NzUtOGNhZC0zYjZiOWUzOTNmMWQ"
# BOT_ACCESS_TOKEN = "OThiZGYxOTEtZTE0Zi00ZTMzLTljMDktOWMyYjIxYzAyZjBkZmI2YTZjNmItZjg0"

'''
Read config.json for BOT data
'''
config = ""
with open('config.json') as config_file:
    config = json.load(config_file)

BOT_ID = config["BOT_ID"]
BOT_ACCESS_TOKEN = config["BOT_ACCESS_TOKEN"]
DIC_SENTIMENTS = {}
DIC_DATES = {}
POSTER_IDS = []

class ChatText:
    def __init__(self, roomId):
        self.roomId = roomId
        self.all = []
        self.texts = []
        self.times = []

        url = "https://api.ciscospark.com/v1/messages?roomId=" + self.roomId
        params = {
            'Authorization': "Bearer ODYyNzQ3ZGYtMTM3Zi00ZmE5LTk3MTctM2U5YjViYTQ4MjFhYzkxZmIzNzUtZGI2",
            'Content-Type': "application/json; charset=utf-8"
        }

        num_iterations = 0
        while True:
            num_iterations += 1
            if num_iterations > 10 or not url:
                break
            r = requests.get(url, headers=params)
            self.json = json.loads(r.text)
            url = r.headers.get('Link', None)
            if url:
                url = url[1:url.find(';') - 1]
            if self.json.get("items", None):
                for item in reversed(self.json["items"]):
                    if item["personId"] not in POSTER_IDS:
                        POSTER_IDS.append(item["personId"])
                    add_to_dictionary(DIC_SENTIMENTS, DIC_DATES, item["posterId"], item["text"], item["created"])
                    self.all.append(item)
                    self.texts.append(item["text"])
                    self.times.append(item["created"])
                make_graph(DIC_SENTIMENTS, DIC_DATES, POSTER_IDS[0])

def sentiment_of_text(id, text):
    dic = {"documents": []}
    dic["documents"].append({"id": id, "text": text})

    uri = 'westus.api.cognitive.microsoft.com'
    path = '/text/analytics/v2.0/sentiment'
    headers = {'Ocp-Apim-Subscription-Key': ACCESS_KEY}
    conn = http.client.HTTPSConnection(uri)
    # body = json.dumps(getLanguage(chatText, accessKey))
    body = json.dumps(dic)
    conn.request("POST", path, body, headers)
    response = conn.getresponse()
    returnedJson = json.loads(response.read().decode('utf-8'))
    if "documents" not in returnedJson:
        print(returnedJson)
        return sentiment_of_text(id, text)
    return (returnedJson["documents"][0]["score"]-.5)*2*GRAPH_SCALE  # if the program errors, try

#   return returnedJson["documents"][0]["detectedLanguages"][0]["score"]

def parse_date(date):
    return datetime.datetime.strptime(date[:19], "%Y-%m-%dT%H:%M:%S")

def add_to_dictionary(dic, dic_dates, id, text, date):
    if id not in dic:
        dic[id] = []
        dic_dates[id] = []
    dic[id].append(sentiment_of_text(id, text))
    dic_dates[id].append(parse_date(date))

def make_graph(dic, dic_dates, id):
    fig = plt.figure()
    plt.plot_date(dic_dates[id], dic[id])
    plt.tight_layout()
    plt.ylim(-GRAPH_SCALE, GRAPH_SCALE)
    plt.show()
    fig.savefig("{} fig.pdf".format(id), bbox_inches='tight')
    return "{} fig.pdf".format(id)

# plots across all IDs
def plot_overall_sentiment(dic, dic_dates):
    fig = plt.figure()
    for id in dic:
        plt.plot_date(dic_dates[id], dic[id])
    plt.tight_layout()
    plt.ylim(-GRAPH_SCALE, GRAPH_SCALE)
    plt.show()
    fig.savefig("{} fig.pdf".format(id), bbox_inches='tight')
    return "{} fig.pdf".format(id)

def createDocument(chatText):
    doc = {'documents': []}
    counter = 1
    for text in chatText.texts:
        doc['documents'].append({'id': str(counter), 'language': 'en', 'text': text})
        counter += 1
    return doc


def createTextStream(chatText):
    textstream = ''
    for text in chatText:
        if type(text) is str:
            textstream += text + ". "
        else:
            textstream += text.decode('utf-8') + ". "
    return textstream


def createTextStreamMicrosoft(chatText):
    doc = {'documents': [
        {
            'id': '1',
            'language': 'en',
            'text': '',
        }
    ]}
    for text in chatText:
        if type(text) is str:
            doc['documents'][0]['text'] += text + ". "
        else:
            doc['documents'][0]['text'] += text.decode('utf-8') + ". "

    return doc


def getSentiment(chatText, accessKey):
    uri = 'westus.api.cognitive.microsoft.com'
    path = '/text/analytics/v2.0/sentiment'

    headers = {'Ocp-Apim-Subscription-Key': accessKey}
    conn = http.client.HTTPSConnection(uri)
    # body = json.dumps(getLanguage(chatText, accessKey))
    doc = createDocument(chatText)
    body = json.dumps(doc)

    conn.request("POST", path, body, headers)
    response = conn.getresponse()
    returnedJson = json.loads(response.read().decode('utf-8'))

    index = 0
    for item in returnedJson['documents']:
        doc['documents'][index]['score'] = item['score']
        index += 1

    return doc['documents']


def getOverallSentiment(messages):
    overall = 0
    size = 0
    for message in messages:
        size += 1
        overall += message['score']
    return overall / size


def getKeyPhrases(chatText, accessKey):
    uri = 'westus.api.cognitive.microsoft.com'
    path = '/text/analytics/v2.0/keyPhrases'

    headers = {'Ocp-Apim-Subscription-Key': accessKey}
    conn = http.client.HTTPSConnection(uri)
    # body = json.dumps(getLanguage(chatText, accessKey))
    body = str(createTextStream(chatText))

    conn.request("POST", path, body, headers)
    response = conn.getresponse()
    returnedJson = json.loads(response.read().decode('utf-8'))

    return returnedJson['documents'][0]['keyPhrases']


def getSummary(chatText):
    body = str(createTextStream(chatText))
    parser = PlaintextParser.from_string(body, Tokenizer("english"))
    stemmer = Stemmer("english")

    summarizer = Summarizer(stemmer)
    summarizer.stop_words = get_stop_words("english")

    return summarizer(parser.document, 5)


def getMessages(roomId):
    # "df53038c-1940-355e-aa24-e4bc8d67b64a"
    return ChatText(roomId)


def outputSentiment(roomId):
    messages = getMessages(roomId)
    return getOverallSentiment(getSentiment(messages, ACCESS_KEY))


def outputSummary(roomId):
    ret = ""
    messages = getMessages(roomId)
    messagesByDate = {}

    for message in messages.all:
        key = message["created"][:10]
        value = message["text"]
        if key not in messagesByDate:
            messagesByDate[key] = []
        messagesByDate[key].append(value)

    # Return message summaries by date
    for k, v in messagesByDate.items():
        # ret += "Summary of the conversation on " + k + ": "
        summaries = getSummary(v)
        for sentence in summaries[4:]:
            ret += str(sentence) + " (" + k + ")"
        ret += "\n"
    # keyPhrases = getKeyPhrases(v, ACCESS_KEY)
    # for phrase in keyPhrases:
    # 	ret += phrase + ", "

    return ret


def outputKeyPhrases(roomId):
    ret = ""
    messages = getMessages(roomId)
    messagesByDate = {}
    for message in messages.all:
        key = message["created"][:10]
        value = message["text"]
        if key not in messagesByDate:
            messagesByDate[key] = []
        messagesByDate[key].append(value)

    # Return message summaries by date
    for k, v in messagesByDate.items():
        keyPhrases = getKeyPhrases(v, ACCESS_KEY)
        isFirst = True
        for phrase in keyPhrases:
            if isFirst:
                isFirst = False
            else:
                ret += ","
            ret += phrase
    return ret + " (" + k + ")"


def output(roomId):
    ret = ""
    messages = getMessages(roomId)

    # Return sentiments
    sentiments = getSentiment(messages, ACCESS_KEY)
    ret += "Your group has an overall sentiment of " + str(getOverallSentiment(sentiments)) + "\n"

    # Group messages by date
    messagesByDate = {}
    for message in messages.all:
        key = message["created"][:10]
        value = message["text"]
        if key not in messagesByDate:
            messagesByDate[key] = []
        if message["personEmail"] != "wothappen@sparkbot.io" and "WotHappen" not in value:
            messagesByDate[key].append(value)

    # Return message summaries by date
    for k, v in messagesByDate.items():
        ret += "Summary of the conversation on " + k + ": "
        summaries = getSummary(v)
        for sentence in summaries[4:]:
            ret += str(sentence)
        ret += "\n"
    # keyPhrases = getKeyPhrases(v, ACCESS_KEY)
    # for phrase in keyPhrases:
    # 	ret += phrase + ", "

    return ret
